<!DOCTYPE html>
<html>
    <head>
        <meta charset ="utf-8"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=0" />
		<title>Data Cleaning</title>

	</head>
    <body>
        <h1 style="text-align:center ;">Data Cleaning of SF Car-Breakins</h1>
        <hr> 
        <h2 style="text-align:left; margin-left: 80px;">Data Cleaning Using R</h2>
        <p style="text-align:left;margin-left: 80px; margin-right: 80px;"> Since of the data source will be the <strong>San Francisco Police Reports</strong> database, this database include all the reported crimes 
            that happenes since 2018 and larcenry (from vehicle) is one of them, so I filtered the dataset and only focus on larcenry from the vechicle. The original dataset is over 10,000 oberservarions, rich and contain multiple informations such as the date,
            times, and days of the week, which I believe I could utilize these day to get a general trend of crime happening, like year to year comparision and day to day comparision for each day of the week. 
            For now I just dropped the useless columns such as "ESNCAG - Boundary File" and "Central Market/Tenderloin Boundary Polygon - Updated" within the dataset and filter the data by time and years for these incidents.
            <br><br>
            I will further combine the data with
            geo-data of the SF neighberhoods and the geo data(GPS points of incident location) and the according neighberhoods where the incident happends included in the dataset to get a more cleared visisualization of the data for the dataset. 
        </p>

        <center><img src="pre_clean.png" alt="Pre-Clean Data" style="width:800px;height:350px;"><br></center>
        <center><p> The Original Data downloaded from the SF police database</p></center>
        <center><img src="post_clean_2019.png" alt="post clean Data 2019" style="width:800px;height:350px;"><br></center>
        <center><p> The Data after pre-clean up using R: All the break-ins happenes in 2019.</p></center>

        <ol style="text-align:left; margin-left: 80px; margin-right: 80px;">
            <li>Link to the R clean up code: <a href="https://github.com/anly501/anly-501-project-YichenG82619/tree/main/codes/02-data-cleaning"> 02-data-cleaning </a></li>
            <li>Link to the clean up data: <a href="https://github.com/anly501/anly-501-project-YichenG82619/tree/main/data"> Github-data </a></li>
          </ol>

        <h2 style="text-align:left; margin-left: 80px;">Text Data Cleaning Using Python:</h2>
        <p style="text-align:left; margin-left: 80px; margin-right: 80px;"> One of the other data sources will be the <strong>Twitter Tweets</strong>, 
            I am expecting to use tweets to track and anlyze the trend of car break-ins
            over time and also using different fields like (location) and (time of the day) to supplement the SF police data source. 
            There are also accounts that keep tracking of car break-ins around SF, which I beleve will be a great source of information.

            <ol style="text-align:left; margin-left: 80px; margin-right: 80px;">
                <li>Link to the Python clean up code: <a href="https://github.com/anly501/anly-501-project-YichenG82619/tree/main/codes/02-data-cleaning"> 02-data-cleaning </a></li>
                <li>Link to the clean up data: <a href="https://github.com/anly501/anly-501-project-YichenG82619/tree/main/data"> Github-data </a></li>
              </ol> 
    <hr>
    <footer>
        <p style="text-align:left; margin-left: 80px; margin-right: 80px;">
            <a href="https://yicheng.georgetown.domains/501-project-website/index.html">Return to the Home page</a>
        </p> 
      </footer>
    </body>
</html>