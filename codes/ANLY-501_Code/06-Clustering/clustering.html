<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.247">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Clustering</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="clustering_files/libs/clipboard/clipboard.min.js"></script>
<script src="clustering_files/libs/quarto-html/quarto.js"></script>
<script src="clustering_files/libs/quarto-html/popper.min.js"></script>
<script src="clustering_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="clustering_files/libs/quarto-html/anchor.min.js"></script>
<link href="clustering_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="clustering_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="clustering_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="clustering_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="clustering_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#theory" id="toc-theory" class="nav-link" data-scroll-target="#theory">Theory</a>
  <ul class="collapse">
  <li><a href="#k-means-clustering" id="toc-k-means-clustering" class="nav-link" data-scroll-target="#k-means-clustering">K-Means Clustering</a></li>
  <li><a href="#dbscan-density-based-spatial-clustering-of-applications-with-noise" id="toc-dbscan-density-based-spatial-clustering-of-applications-with-noise" class="nav-link" data-scroll-target="#dbscan-density-based-spatial-clustering-of-applications-with-noise">DBSCAN (Density-based Spatial Clustering of Applications with Noise)</a></li>
  <li><a href="#hierarchical-agglomerative-vs-divisive-clustering" id="toc-hierarchical-agglomerative-vs-divisive-clustering" class="nav-link" data-scroll-target="#hierarchical-agglomerative-vs-divisive-clustering">Hierarchical (Agglomerative vs Divisive) Clustering</a></li>
  </ul></li>
  <li><a href="#method" id="toc-method" class="nav-link" data-scroll-target="#method">Method</a>
  <ul class="collapse">
  <li><a href="#data-selection-and-preparation" id="toc-data-selection-and-preparation" class="nav-link" data-scroll-target="#data-selection-and-preparation">Data Selection and preparation</a></li>
  </ul></li>
  <li><a href="#perform-k-means-clustering" id="toc-perform-k-means-clustering" class="nav-link" data-scroll-target="#perform-k-means-clustering">Perform K-means clustering</a>
  <ul class="collapse">
  <li><a href="#hyper-parameter-tuning-with-elbow-method" id="toc-hyper-parameter-tuning-with-elbow-method" class="nav-link" data-scroll-target="#hyper-parameter-tuning-with-elbow-method">Hyper-parameter tuning with elbow method</a></li>
  <li><a href="#dimensional-reduction-and-final-result-visualization" id="toc-dimensional-reduction-and-final-result-visualization" class="nav-link" data-scroll-target="#dimensional-reduction-and-final-result-visualization">Dimensional reduction and Final Result Visualization</a></li>
  </ul></li>
  <li><a href="#perform-dbscan" id="toc-perform-dbscan" class="nav-link" data-scroll-target="#perform-dbscan">Perform DBSCAN</a>
  <ul class="collapse">
  <li><a href="#hyper-parameter-tuning-with-silhouette" id="toc-hyper-parameter-tuning-with-silhouette" class="nav-link" data-scroll-target="#hyper-parameter-tuning-with-silhouette">Hyper-parameter tuning with Silhouette</a></li>
  <li><a href="#final-results" id="toc-final-results" class="nav-link" data-scroll-target="#final-results">Final Results</a></li>
  </ul></li>
  <li><a href="#perform-hierarchical-clustering" id="toc-perform-hierarchical-clustering" class="nav-link" data-scroll-target="#perform-hierarchical-clustering">Perform Hierarchical clustering</a>
  <ul class="collapse">
  <li><a href="#hyper-parameters-tuning" id="toc-hyper-parameters-tuning" class="nav-link" data-scroll-target="#hyper-parameters-tuning">Hyper-parameters tuning</a></li>
  <li><a href="#final-results-and-visualization." id="toc-final-results-and-visualization." class="nav-link" data-scroll-target="#final-results-and-visualization.">Final Results and visualization.</a></li>
  </ul></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">Results</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  <li><a href="#reference" id="toc-reference" class="nav-link" data-scroll-target="#reference">Reference</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Clustering</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Similiar to previous tab, the dataset I will apply clustering with will be the twitter crime report I have collected. Since the break-in crimes reported by SFPD in previous years are majorly categorical data like report type, location and value of good lost, which k mean clustersing aren’t able to handle these <strong>discrete data</strong> and generate the distance between the data points, so in this application of clustering we will focus on the twitter crime report dataset. The feature for clustering will be vectorized text and will be compared with the labeled text to see how are the unsuprvised clustering compared with others.</p>
</section>
<section id="theory" class="level2">
<h2 class="anchored" data-anchor-id="theory">Theory</h2>
<section id="k-means-clustering" class="level3">
<h3 class="anchored" data-anchor-id="k-means-clustering">K-Means Clustering</h3>
<p>K-Means Clustering is one of the most known and used unsupervised algortithms (no targeted labels) in data science and is used to group a set of data into a defined number of groups. However, the process of this algorithms is relatively simple. The algorithm initializes random positions (called centroids, the red, blue and green points in the picture below) in the vector plane and assigns the point to the nearest centroid. The algorithm calculates the average position (or, <strong>distance</strong>) of the points to the center of the data points (centroid), and moves the respective centroid to that position and updates the group to which each point belongs. The algorithm converges when all points are at the minimum distance from their respective centroid.</p>
<p>Its worthly to notice that This distance is often measured in <strong>Euclidean Distance</strong> (Distance = <span class="math inline">\(\sqrt{(x_1 - y_1)^2+(x_2 - y_2)^2+...+(x_n - y_n)^2}\)</span>) but there are some expectations.</p>
<br><br> <img src="kmeans1.png" class="img-fluid">
<center>
<em>Initialized the centroids</em>
</center>
<p><br><br></p>
<blockquote class="blockquote">
<ul>
<li>First Step: Initializtion k centroids from the dataset</li>
<li>Compute the distance of points to the centroids, assign the position of the centroids.</li>
<li>Repeat these steps. Stop till covereged or the stopping criteria is met.</li>
</ul>
</blockquote>
<br><br> <img src="kmeans2.png" class="img-fluid">
<center>
<em>stop untill coverges</em>
</center>
<p><br><br></p>
<p>The stopping criteria is when:</p>
<blockquote class="blockquote">
<ul>
<li>Centroids of newly formed clusters don’t change (convergence)</li>
<li>Data points remain in the same cluster</li>
<li>Maximum number of iterations are reached</li>
</ul>
</blockquote>
<p>Desipte been the most used unsupervised learning algorhtims, K-Means clustering does have its limitations, the main drawback that it is sensitive to poor initializiation of clusters, which could lead to the optimal points being stuck in a local optimum space. Yet, K-Means is still an interpretable, efficient, clustering algorthims that guarantees an approximation, and works well for clusters having similar properties.</p>
</section>
<section id="dbscan-density-based-spatial-clustering-of-applications-with-noise" class="level3">
<h3 class="anchored" data-anchor-id="dbscan-density-based-spatial-clustering-of-applications-with-noise">DBSCAN (Density-based Spatial Clustering of Applications with Noise)</h3>
<p>DBSCAN is clustering method that is used in machine learning to <strong>separate clusters</strong> of high density from clusters of low density region. It is useful when the clusters are irregular or non-spherical, for example, or when noise and outliers are present in the features. Its a very efficient clustering algorithm as it groups together points that are closely packed together (points with many nearby neighbors), this closeness is called the radius of <span class="math inline">\(\epsilon\)</span>, which is the distance measure used to locate the points in the surrounding neighbors. Anohter parameters that could been used to min_samples, which is the minium number of points to include in each search.</p>
<br><br> <img src="db.png" class="img-fluid">
<center>
<em>the difference between DBSCAN and K-means</em>
</center>
<p><br><br></p>
<p>Although both DBSCAN and k=means are unsupervised algothrims that could handle complex data, they are not the same. As shown in the figure above, DBSCAN focus on the density of the data points, where the K-means are determine by the distance between each datasets, thus DBSCAN can locate non-linearly separable clusters but K-Means cannot. Moreover, unlike K-Means, there is no need to specify the number of clusters “k” when employing DBSCAN. However, choosing a value for <span class="math inline">\(\epsilon\)</span> is more difficult than choosing a good initial value for “k” for K-Means because <span class="math inline">\(\epsilon\)</span> is less intuitive to reason.</p>
</section>
<section id="hierarchical-agglomerative-vs-divisive-clustering" class="level3">
<h3 class="anchored" data-anchor-id="hierarchical-agglomerative-vs-divisive-clustering">Hierarchical (Agglomerative vs Divisive) Clustering</h3>
<p>Hierarchical clustering, or so called technique is different from Partitional clustering, which divides the data into non-overlapping clusters and form a hierarchy of cluster. The results of hierarchical clustering are usually presented in a dendrogram, a tree-like diagram showing hierarchical relationships between different sets of data. The dendrogram can be used to decide when to stop merging the clusters or, in other words, finding the optimal number of clusters. We cut the dendrogram tree with a threshold at a height where the threshold line can traverse the maximum distance up and down without intersecting the merging point.</p>
<br><br> <img src="hier.png" class="img-fluid">
<center>
<em>the overview of hierarchical clustering</em>
</center>
<p><br><br></p>
<p>There exist two main types of hierarchical clustering: &gt;- Agglomerative clustering (bottom up): Start with the points as individual clusters. At each step, move up the hierarchy by merging the closest pair of clusters until only one cluster is left. &gt;- Divisive clustering (top down): All observations start in one, all-inclusive cluster. At each step, move down the hierarchy by splitting a cluster recursively until each cluster contains a point. Therefore, this approach is exactly opposite to Agglomerative clustering.</p>
<p>Hierarchical clustering, unlike K-Means, does not require initializing the number of clusters apriori and any valid measure of distance could be used to decide the relationship between each data points. However, on the other hand, this means hierarchical clustering are more sensitive to outliers and often take more space and time to compute compare to other faster algorthims like the k-means.</p>
</section>
</section>
<section id="method" class="level2">
<h2 class="anchored" data-anchor-id="method">Method</h2>
<section id="data-selection-and-preparation" class="level3">
<h3 class="anchored" data-anchor-id="data-selection-and-preparation">Data Selection and preparation</h3>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># import libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># string manipulation libs</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> string</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'punkt'</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'stopwords'</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> stopwords</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>[nltk_data] Downloading package punkt to
[nltk_data]     /Users/yanweitong/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package stopwords to
[nltk_data]     /Users/yanweitong/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!</code></pre>
</div>
</div>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> preprocess_text(text: <span class="bu">str</span>, remove_stopwords: <span class="bu">bool</span>) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""This function cleans the input text by</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">    - removing links</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co">    - removing special chars</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">    - removing numbers</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co">    - removing stopwords</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">    - transforming in lower case</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co">    - removing excessive whitespaces</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Arguments:</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co">        text (str): text to clean</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co">        remove_stopwords (bool): remove stopwords or not</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co">        str: cleaned text</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># remove links</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> re.sub(<span class="vs">r"http\S+"</span>, <span class="st">""</span>, text)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># remove numbers and special chars</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> re.sub(<span class="st">"[^A-Za-z]+"</span>, <span class="st">" "</span>, text)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># remove stopwords</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> remove_stopwords:</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 1. creates tokens</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>        tokens <span class="op">=</span> nltk.word_tokenize(text)</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 2. checks if token is a stopword and removes it</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>        tokens <span class="op">=</span> [w <span class="cf">for</span> w <span class="kw">in</span> tokens <span class="cf">if</span> <span class="kw">not</span> w.lower() <span class="kw">in</span> stopwords.words(<span class="st">"english"</span>)]</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 3. joins all tokens again</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> <span class="st">" "</span>.join(tokens)</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># returns cleaned text</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> text.lower().strip()</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> text</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Since tweets including a lot of meaningless stopwords and symbol in the corpus, we use NLTK libirary to import the stopwords and write a function that takes some text as input and returns a clean verision of it.</p>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load the data </span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>df<span class="op">=</span>pd.read_csv(<span class="st">"../../data/01-modified-data/breakin_prediction.csv"</span>, encoding <span class="op">=</span> <span class="st">"ISO-8859-1"</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'cleaned'</span>] <span class="op">=</span> df[<span class="st">'text'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: preprocess_text(x, remove_stopwords<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="3">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>text</th>
      <th>label</th>
      <th>cleaned</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>no mention yet of the Libs own lawyer resignin...</td>
      <td>0</td>
      <td>mention yet libs lawyer resigning saying may b...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>I want Spidey back. After NWH, my heart broken...</td>
      <td>0</td>
      <td>want spidey back nwh heart broken pieces</td>
    </tr>
    <tr>
      <th>2</th>
      <td>The owner of a Vancouver butcher shop is calli...</td>
      <td>0</td>
      <td>owner vancouver butcher shop calling city take...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>He had thought she looked cool her eyes shone ...</td>
      <td>0</td>
      <td>thought looked cool eyes shone like cats eyes ...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>nose got broken at a show he popped it back in...</td>
      <td>0</td>
      <td>nose got broken show popped back place</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>95</th>
      <td>For those without a calculator, thatÕs a getti...</td>
      <td>1</td>
      <td>without calculator getting robbed batting aver...</td>
    </tr>
    <tr>
      <th>96</th>
      <td>dreamt someone stole my catalytic converter. W...</td>
      <td>1</td>
      <td>dreamt someone stole catalytic converter sitti...</td>
    </tr>
    <tr>
      <th>97</th>
      <td>To the lady who had her rear window smashed in...</td>
      <td>1</td>
      <td>lady rear window smashed everything valuable s...</td>
    </tr>
    <tr>
      <th>98</th>
      <td>donÕt leave anything visible in your car. It w...</td>
      <td>1</td>
      <td>leave anything visible car result broken windo...</td>
    </tr>
    <tr>
      <th>99</th>
      <td>Just broke a blue car's window to take some fr...</td>
      <td>1</td>
      <td>broke blue car window take free stuff san fran...</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 3 columns</p>
</div>
</div>
</div>
<p>Now since the text has been cleaned, we are ready for text vectorization. They way we vectorized the text is through <strong>TF-IDF Vectorization</strong>, which converts our corpus into a numerical format by bringing out specific terms, weighing very rare or very common terms differently in order to assign them a low score. With this vectorization technique we are able to group our documents considering the most important terms that constitute them.</p>
<div class="cell" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize the vectorizer</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>vectorizer <span class="op">=</span> TfidfVectorizer(sublinear_tf<span class="op">=</span><span class="va">True</span>, min_df<span class="op">=</span><span class="dv">5</span>, max_df<span class="op">=</span><span class="fl">0.95</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># fit_transform applies TF-IDF to clean texts - we save the array of vectors in X</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> vectorizer.fit_transform(df[<span class="st">'cleaned'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
<section id="perform-k-means-clustering" class="level2">
<h2 class="anchored" data-anchor-id="perform-k-means-clustering">Perform K-means clustering</h2>
<div class="cell" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># import relevent libraries for clustering</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statistics <span class="im">import</span> mode</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.spatial.distance <span class="im">import</span> cdist</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize kmeans with 2 centroids</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans().fit(X)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co"># store cluster labels in a variable</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>clusters <span class="op">=</span> kmeans.labels_</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize PCA with 2 components</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co"># pass X to the pca</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>pca_vecs <span class="op">=</span> pca.fit_transform(X.toarray())</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co"># save the two dimensions in x0 and x1</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>x0 <span class="op">=</span> pca_vecs[:, <span class="dv">0</span>]</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> pca_vecs[:, <span class="dv">1</span>]</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="co"># assign clusters and PCA vectors to columns in the original dataframe</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'cluster'</span>] <span class="op">=</span> clusters</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'x0'</span>] <span class="op">=</span> x0</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'x1'</span>] <span class="op">=</span> x1</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>fig,ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">6</span>), dpi<span class="op">=</span><span class="dv">150</span>)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span><span class="st">"x0"</span>, y<span class="op">=</span><span class="st">"x1"</span>, hue<span class="op">=</span><span class="st">"label"</span>, data<span class="op">=</span> df, ax<span class="op">=</span>ax[<span class="dv">0</span>])</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span><span class="st">"x0"</span>, y<span class="op">=</span><span class="st">"x1"</span>, hue<span class="op">=</span><span class="st">"cluster"</span>, data<span class="op">=</span> df, ax<span class="op">=</span>ax[<span class="dv">1</span>])</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_title(<span class="st">"True Clusters"</span>)</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_title(<span class="st">"Predicted Clusters"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>Text(0.5, 1.0, 'Predicted Clusters')</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="clustering_files/figure-html/cell-6-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>With sk learn’s default parametes, the dataset was split into 6 different groups compare to the actual 2 groups, thus the further tuning of the hyper-parameters is needed in this case.</p>
<section id="hyper-parameter-tuning-with-elbow-method" class="level3">
<h3 class="anchored" data-anchor-id="hyper-parameter-tuning-with-elbow-method">Hyper-parameter tuning with elbow method</h3>
<p>For K means clustering we will use the elbow emethod to find the optimal number of clusters. we will use the inertia_ attribute to find the sum of squared distances of samples to their closest cluster center. We will use the range of 1 to 15 clusters, then we will plot the inertia_ values for each number of clusters.</p>
<div class="cell" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># elbow method</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>X1<span class="op">=</span> X.toarray() </span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>X1.shape</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>distortions <span class="op">=</span> []</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>inertias <span class="op">=</span> []</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>k<span class="op">=</span><span class="dv">11</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, k):</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    kmeanModel <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, init<span class="op">=</span><span class="st">"k-means++"</span>, random_state<span class="op">=</span> <span class="dv">42</span>)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    kmeanModel.fit(X1)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    distortions.append(<span class="bu">sum</span>(np.<span class="bu">min</span>(cdist(X1, kmeanModel.cluster_centers_, <span class="st">'euclidean'</span>), axis<span class="op">=</span> <span class="dv">1</span>))<span class="op">/</span>X1.shape[<span class="dv">0</span>])</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    inertias.append(kmeanModel.inertia_)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    evaluation <span class="op">=</span> pd.DataFrame.from_records({<span class="st">'Cluster'</span>:np.arange(<span class="dv">1</span>,k<span class="op">+</span><span class="dv">1</span>),<span class="st">'Distorion'</span>:distortions,<span class="st">'Inertias'</span>:inertias})</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>evaluation</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="6">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Cluster</th>
      <th>Distorion</th>
      <th>Inertias</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0.863817</td>
      <td>77.418274</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>0.783387</td>
      <td>65.773686</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>0.747138</td>
      <td>61.544495</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>0.682415</td>
      <td>57.367545</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0.650095</td>
      <td>52.790723</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>0.623971</td>
      <td>48.890915</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>0.602274</td>
      <td>46.072799</td>
    </tr>
    <tr>
      <th>7</th>
      <td>8</td>
      <td>0.573104</td>
      <td>42.587209</td>
    </tr>
    <tr>
      <th>8</th>
      <td>9</td>
      <td>0.558887</td>
      <td>40.841607</td>
    </tr>
    <tr>
      <th>9</th>
      <td>10</td>
      <td>0.531595</td>
      <td>37.269390</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="7">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>evaluation.plot.line(x<span class="op">=</span><span class="st">'Cluster'</span>, subplots<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>array([&lt;AxesSubplot:xlabel='Cluster'&gt;, &lt;AxesSubplot:xlabel='Cluster'&gt;],
      dtype=object)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="clustering_files/figure-html/cell-8-output-2.png" width="571" height="422"></p>
</div>
</div>
<p>As we see from the graph, as the number of cluster increase, the distortions and inertias naturally decreases, however, when the number of cluster = 2, the graph turns flat for the first time, thus 2 might be the best number of cluster in this analysis, which is also similiar to our actual label of the dataset.</p>
<div class="cell" data-execution_count="8">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize kmeans with 2 centroids</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co"># fit the model</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>kmeans.fit(X)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># store cluster labels in a variable</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>clusters <span class="op">=</span> kmeans.labels_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="dimensional-reduction-and-final-result-visualization" class="level3">
<h3 class="anchored" data-anchor-id="dimensional-reduction-and-final-result-visualization">Dimensional reduction and Final Result Visualization</h3>
<p>Since it’s impossible to plot something greater than 3 dimensions, and if we look at the dimension of x with X.shape we see that it is (100,26). There are 100 vectors for each text and each with 26 dimensions, thus its impossible for visual comparison.</p>
<p>Fortunately, there is a technique called <strong>PCA (Principal Component Analysis)</strong> which reduces the dimensionality of a data set to an arbitrary number while preserving most of the information contained in it. Thus we can run PCA to reduce the dimension of the clusterd and easy to visualization.</p>
<div class="cell" data-execution_count="9">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize PCA with 2 components</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># pass X to the pca</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>pca_vecs <span class="op">=</span> pca.fit_transform(X.toarray())</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co"># save the two dimensions in x0 and x1</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>x0 <span class="op">=</span> pca_vecs[:, <span class="dv">0</span>]</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> pca_vecs[:, <span class="dv">1</span>]</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co"># assign clusters and PCA vectors to columns in the original dataframe</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'cluster'</span>] <span class="op">=</span> clusters</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'x0'</span>] <span class="op">=</span> x0</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'x1'</span>] <span class="op">=</span> x1</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>cluster_map <span class="op">=</span> {<span class="dv">0</span>: <span class="st">"non_crime"</span>, <span class="dv">1</span>: <span class="st">"crime"</span>} <span class="co"># mapping found through get_top_keywords</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'cluster'</span>] <span class="op">=</span> df[<span class="st">'cluster'</span>].<span class="bu">map</span>(cluster_map)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>fig,ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">6</span>), dpi<span class="op">=</span><span class="dv">150</span>)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span><span class="st">"x0"</span>, y<span class="op">=</span><span class="st">"x1"</span>, hue<span class="op">=</span><span class="st">"label"</span>, data<span class="op">=</span> df, ax<span class="op">=</span>ax[<span class="dv">0</span>])</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span><span class="st">"x0"</span>, y<span class="op">=</span><span class="st">"x1"</span>, hue<span class="op">=</span><span class="st">"cluster"</span>, data<span class="op">=</span> df, ax<span class="op">=</span>ax[<span class="dv">1</span>])</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_title(<span class="st">"True Clusters"</span>)</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_title(<span class="st">"Predicted Clusters"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>Text(0.5, 1.0, 'Predicted Clusters')</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="clustering_files/figure-html/cell-10-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>As we can see from the graph above, the k-means clustering with k=2 is perfoming excellently compare to the the True clusters.</p>
</section>
</section>
<section id="perform-dbscan" class="level2">
<h2 class="anchored" data-anchor-id="perform-dbscan">Perform DBSCAN</h2>
<section id="hyper-parameter-tuning-with-silhouette" class="level3">
<h3 class="anchored" data-anchor-id="hyper-parameter-tuning-with-silhouette">Hyper-parameter tuning with Silhouette</h3>
<p>Major challenge of using DBSCAN algorithm is to find right set hyper parameters(eps and min_samples values) to fit in to the algorithm for getting accurate result. And Silhouette metric is a distance calculation algorithm using euclidean or Manhattan distance. A Silhouette Score always ranges between -1 to 1. A high Silhouette score suggests that the objects are well matched to their own cluster and poorly matched to their neighborhood clusters. Thus this will be the way to to find the optimal eps and min_sample values.</p>
<div class="cell" data-execution_count="10">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># perform DBSCAN clustering. use the eps and min_samples parameters to find the optimal number of clusters.</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> DBSCAN</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_samples, silhouette_score</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Defining the list of hyperparameters to try</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>eps_list<span class="op">=</span>np.arange(start<span class="op">=</span><span class="fl">0.1</span>, stop<span class="op">=</span><span class="fl">4.1</span>, step<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>min_sample_list<span class="op">=</span>np.arange(start<span class="op">=</span><span class="dv">5</span>, stop<span class="op">=</span><span class="dv">10</span>, step<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating empty data frame to store the silhouette scores for each trials</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>sil_score_data <span class="op">=</span> pd.DataFrame()</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> eps_trial <span class="kw">in</span> eps_list:</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> min_sample_trial <span class="kw">in</span> min_sample_list:</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Generating DBSAN clusters</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>        db <span class="op">=</span> DBSCAN(eps<span class="op">=</span>eps_trial, min_samples<span class="op">=</span>min_sample_trial)</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(<span class="bu">len</span>(np.unique(db.fit_predict(X)))<span class="op">&gt;=</span><span class="dv">2</span>):</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>            sil_score<span class="op">=</span>silhouette_score(X, db.fit_predict(X))</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>        trial_parameters<span class="op">=</span><span class="st">"eps:"</span> <span class="op">+</span> <span class="bu">str</span>(eps_trial.<span class="bu">round</span>(<span class="dv">1</span>)) <span class="op">+</span><span class="st">", min_sample:"</span> <span class="op">+</span> <span class="bu">str</span>(min_sample_trial)</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>        sil_score_data<span class="op">=</span>pd.concat([sil_score_data, pd.DataFrame(data<span class="op">=</span>[[sil_score,trial_parameters]], columns<span class="op">=</span>[<span class="st">"score"</span>, <span class="st">"parameters"</span>])])</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Finding out the best hyperparameters with highest Score</span></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>sil_score_data.sort_values(by<span class="op">=</span><span class="st">'score'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="10">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>score</th>
      <th>parameters</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.160067</td>
      <td>eps:0.9, min_sample:7</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.120461</td>
      <td>eps:0.9, min_sample:6</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.112747</td>
      <td>eps:0.9, min_sample:8</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.105726</td>
      <td>eps:0.9, min_sample:5</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.051082</td>
      <td>eps:0.1, min_sample:5</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.051082</td>
      <td>eps:0.5, min_sample:8</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.051082</td>
      <td>eps:0.7, min_sample:9</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.051082</td>
      <td>eps:0.7, min_sample:8</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.051082</td>
      <td>eps:0.7, min_sample:7</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.051082</td>
      <td>eps:0.7, min_sample:6</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.051082</td>
      <td>eps:0.7, min_sample:5</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.051082</td>
      <td>eps:0.5, min_sample:9</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.051082</td>
      <td>eps:0.5, min_sample:7</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.051082</td>
      <td>eps:0.1, min_sample:6</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.051082</td>
      <td>eps:0.5, min_sample:6</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.051082</td>
      <td>eps:0.5, min_sample:5</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.051082</td>
      <td>eps:0.3, min_sample:9</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.051082</td>
      <td>eps:0.3, min_sample:8</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.051082</td>
      <td>eps:0.3, min_sample:7</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.051082</td>
      <td>eps:0.3, min_sample:6</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.051082</td>
      <td>eps:0.3, min_sample:5</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.051082</td>
      <td>eps:0.1, min_sample:9</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.051082</td>
      <td>eps:0.1, min_sample:8</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.051082</td>
      <td>eps:0.1, min_sample:7</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.051082</td>
      <td>eps:0.9, min_sample:9</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>From the table we can tell that the best parameters for this model will be eps =0.7, and min number of samples be 7.</p>
</section>
<section id="final-results" class="level3">
<h3 class="anchored" data-anchor-id="final-results">Final Results</h3>
<div class="cell" data-execution_count="11">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> DBSCAN(eps<span class="op">=</span> <span class="fl">0.9</span>, min_samples<span class="op">=</span><span class="dv">7</span>).fit(X)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>labels_DB <span class="op">=</span> model.labels_</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize PCA with 2 components</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co"># pass X to the pca</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>pca_vecs <span class="op">=</span> pca.fit_transform(X.toarray())</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co"># save the two dimensions in x0 and x1</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> pca_vecs[:, <span class="dv">0</span>]</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>x3 <span class="op">=</span> pca_vecs[:, <span class="dv">1</span>]</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="co"># assign clusters and PCA vectors to columns in the original dataframe</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'DB_labels'</span>]<span class="op">=</span> labels_DB</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'x2'</span>] <span class="op">=</span> x2</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'x3'</span>] <span class="op">=</span> x3</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>fig,ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">6</span>), dpi<span class="op">=</span><span class="dv">150</span>)</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span><span class="st">"x2"</span>, y<span class="op">=</span><span class="st">"x3"</span>, hue<span class="op">=</span><span class="st">"label"</span>, data<span class="op">=</span> df, ax<span class="op">=</span>ax[<span class="dv">0</span>])</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span><span class="st">"x2"</span>, y<span class="op">=</span><span class="st">"x3"</span>, hue<span class="op">=</span><span class="st">"DB_labels"</span>, data<span class="op">=</span> df, ax<span class="op">=</span>ax[<span class="dv">1</span>])</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_title(<span class="st">"True Clusters"</span>)</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_title(<span class="st">"Predicted Clusters"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>Text(0.5, 1.0, 'Predicted Clusters')</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="clustering_files/figure-html/cell-12-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>As the graph has demonstrate, DBSCAN is not a great method when predicting the twitter crime report dataset, since most data pionts are left unidentified and it got the number of the cluster wrong. However, since DBSCAN is to <strong>separate clusters</strong> of high density from clusters of low density region, it’s reasonable to see this kind of performance.</p>
</section>
</section>
<section id="perform-hierarchical-clustering" class="level2">
<h2 class="anchored" data-anchor-id="perform-hierarchical-clustering">Perform Hierarchical clustering</h2>
<div class="cell" data-execution_count="12">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.cluster.hierarchy <span class="im">import</span> dendrogram, linkage</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> AgglomerativeClustering</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AgglomerativeClustering().fit(X.toarray())</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>HC_labels<span class="op">=</span> model.labels_</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'HC_labels'</span>]<span class="op">=</span> HC_labels</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize PCA with 2 components</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co"># pass X to the pca</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>pca_vecs <span class="op">=</span> pca.fit_transform(X.toarray())</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co"># save the two dimensions in x0 and x1</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>x4 <span class="op">=</span> pca_vecs[:, <span class="dv">0</span>]</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>x5 <span class="op">=</span> pca_vecs[:, <span class="dv">1</span>]</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a><span class="co"># assign clusters and PCA vectors to columns in the original dataframe</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'DB_labels'</span>]<span class="op">=</span> labels_DB</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'x4'</span>] <span class="op">=</span> x4</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'x5'</span>] <span class="op">=</span> x5</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>fig,ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">6</span>), dpi<span class="op">=</span><span class="dv">150</span>)</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span><span class="st">"x4"</span>, y<span class="op">=</span><span class="st">"x5"</span>, hue<span class="op">=</span><span class="st">"label"</span>, data<span class="op">=</span> df, ax<span class="op">=</span>ax[<span class="dv">0</span>])</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span><span class="st">"x4"</span>, y<span class="op">=</span><span class="st">"x5"</span>, hue<span class="op">=</span><span class="st">"DB_labels"</span>, data<span class="op">=</span> df, ax<span class="op">=</span>ax[<span class="dv">1</span>])</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_title(<span class="st">"True Clusters"</span>)</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_title(<span class="st">"Predicted Clusters"</span>)</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a> <span class="co">### Plot the clusters for Agglomerative Clustering</span></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a><span class="co"># create linkage for agglomerative clustering, and the dendrogram for the linkage. </span></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> linkage(X.toarray(), method<span class="op">=</span><span class="st">'ward'</span>) <span class="co"># linkage computed using euclidean distance  </span></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>dend <span class="op">=</span> dendrogram(Z)</span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Index'</span>)</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Ward Distance"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>Text(0, 0.5, 'Ward Distance')</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="clustering_files/figure-html/cell-13-output-2.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="clustering_files/figure-html/cell-13-output-3.png" width="799" height="780"></p>
</div>
</div>
<p>Before get staight into hyper-parameter tunning, we could run the hierarchical clustering with a default set of parameters (linkage = ward). As we can see from the graph, depends on where we set the thershold, the dataset could be split into 2 to multiple clusters with ward method.</p>
<section id="hyper-parameters-tuning" class="level3">
<h3 class="anchored" data-anchor-id="hyper-parameters-tuning">Hyper-parameters tuning</h3>
<p>The parameter we are able to adjust are the linkage method(single, complete, average, centroid, ward), and affinity(“euclidean”, “l1”, “l2”, “manhattan”, “cosine”, or “precomputed”), the number of clustering won’t be adjusted since we want the cluster to stay the default 2 clusters.</p>
<p>However, after playing around with different hyper-parameters, the prediction labels <strong>won’t changed</strong> compare to the default setting. For example, as the graph shown below the agglomerative clustering with affinity=‘manhattan’,linkage=‘complete’ predict the exactly similiar result as the default parameters, affinity = eucilidean and linkage = ward. Thus, hyper-parameter tuning is not effective when dealing with twitter crime report dataset.</p>
<div class="cell" data-execution_count="13">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform Agglomerative Clustering</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.cluster.hierarchy <span class="im">import</span> dendrogram, linkage</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> AgglomerativeClustering</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AgglomerativeClustering(n_clusters<span class="op">=</span><span class="dv">2</span>, affinity<span class="op">=</span><span class="st">'manhattan'</span>,linkage<span class="op">=</span><span class="st">'complete'</span>).fit(X.toarray())</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>HC_labels<span class="op">=</span> model.labels_</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'HC_labels'</span>]<span class="op">=</span> HC_labels</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize PCA with 2 components</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="co"># pass X to the pca</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>pca_vecs <span class="op">=</span> pca.fit_transform(X.toarray())</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="co"># save the two dimensions in x0 and x1</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>x4 <span class="op">=</span> pca_vecs[:, <span class="dv">0</span>]</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>x5 <span class="op">=</span> pca_vecs[:, <span class="dv">1</span>]</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a><span class="co"># assign clusters and PCA vectors to columns in the original dataframe</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'DB_labels'</span>]<span class="op">=</span> labels_DB</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'x4'</span>] <span class="op">=</span> x4</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'x5'</span>] <span class="op">=</span> x5</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>fig,ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">6</span>), dpi<span class="op">=</span><span class="dv">150</span>)</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span><span class="st">"x4"</span>, y<span class="op">=</span><span class="st">"x5"</span>, hue<span class="op">=</span><span class="st">"label"</span>, data<span class="op">=</span> df, ax<span class="op">=</span>ax[<span class="dv">0</span>])</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span><span class="st">"x4"</span>, y<span class="op">=</span><span class="st">"x5"</span>, hue<span class="op">=</span><span class="st">"DB_labels"</span>, data<span class="op">=</span> df, ax<span class="op">=</span>ax[<span class="dv">1</span>])</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_title(<span class="st">"True Clusters"</span>)</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_title(<span class="st">"Predicted Clusters"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>Text(0.5, 1.0, 'Predicted Clusters')</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="clustering_files/figure-html/cell-14-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="final-results-and-visualization." class="level3">
<h3 class="anchored" data-anchor-id="final-results-and-visualization.">Final Results and visualization.</h3>
<div class="cell" data-execution_count="14">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform Agglomerative Clustering</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.cluster.hierarchy <span class="im">import</span> dendrogram, linkage</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> AgglomerativeClustering</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AgglomerativeClustering(n_clusters<span class="op">=</span><span class="dv">2</span>, affinity<span class="op">=</span><span class="st">'manhattan'</span>,linkage<span class="op">=</span><span class="st">'complete'</span>).fit(X.toarray())</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>HC_labels<span class="op">=</span> model.labels_</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'HC_labels'</span>]<span class="op">=</span> HC_labels</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize PCA with 2 components</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="co"># pass X to the pca</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>pca_vecs <span class="op">=</span> pca.fit_transform(X.toarray())</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="co"># save the two dimensions in x0 and x1</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>x4 <span class="op">=</span> pca_vecs[:, <span class="dv">0</span>]</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>x5 <span class="op">=</span> pca_vecs[:, <span class="dv">1</span>]</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a><span class="co"># assign clusters and PCA vectors to columns in the original dataframe</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'DB_labels'</span>]<span class="op">=</span> labels_DB</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'x4'</span>] <span class="op">=</span> x4</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'x5'</span>] <span class="op">=</span> x5</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>fig,ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">6</span>), dpi<span class="op">=</span><span class="dv">150</span>)</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span><span class="st">"x4"</span>, y<span class="op">=</span><span class="st">"x5"</span>, hue<span class="op">=</span><span class="st">"label"</span>, data<span class="op">=</span> df, ax<span class="op">=</span>ax[<span class="dv">0</span>])</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span><span class="st">"x4"</span>, y<span class="op">=</span><span class="st">"x5"</span>, hue<span class="op">=</span><span class="st">"DB_labels"</span>, data<span class="op">=</span> df, ax<span class="op">=</span>ax[<span class="dv">1</span>])</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_title(<span class="st">"True Clusters"</span>)</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_title(<span class="st">"Predicted Clusters"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>Text(0.5, 1.0, 'Predicted Clusters')</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="clustering_files/figure-html/cell-15-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>As the graph has demonstrate, agglomerative <strong>is not</strong> a great method when predicting the twitter crime report dataset, since most data pionts are left unidentified and it got the number of the cluster wrong, spliting the dataset into 5 groups despite chaning the parameters. However, since hierarchical clustering used to <strong>group objects</strong> in clusters based on their similarity., it’s reasonable to see this kind of performance.</p>
</section>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>We performed clustering using three different models, including K-Means, DBSCAN, and Agglomerative Clustering. Each model was run twice, before and after the hyper=parameter tunning to the ideal stage. However, not all model received significant change in their accuacy when comparing to the orginal dataset labels.</p>
<p>K-means is surely the most accurate unsupervised clustering method out of the three method we tested today. The final result of the K-Means model was based off on the outputs of the elbow method and the ideal number of clustering is 2. After dimension reduction with PCA, we are able to plot the graph of the prediction which is relatively close to the original labels of crime and none crime. The improvement of hyper-parameters tuning is surprisingly good compared to the other two.</p>
<p>Both DBSCAN and Agglomerative/Hierarchical clustering did a poor job when clustering the dataset, altough both were managed to produced similiar number of clustering, 5. Hyperparameter tunning has little or no effect on the prediction of the labels(crime or not crime) for these two model.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>For this particular dataset, the twitter crime report(textual data), <strong>K-means clustering</strong> perfom the best and was able to generate the prediction of the tweets with label relatively clost to the actualy labels of each dataset. This conclusion might not be inclusive since for textual data after vectorization, the dimension of the matrix could played an effected in the model’s performance of clustering each tweets. DBSCAN and Agglomerative/Hierarchical clustering both are useful clustering method when targeting specific distribution of the dataset and their focus of relationships between each dataset is also different.</p>
</section>
<section id="reference" class="level2">
<h2 class="anchored" data-anchor-id="reference">Reference</h2>
<blockquote class="blockquote">
<ul>
<li>Santini, Marina. “Advantages<em>&amp;</em>Disadvantages*of** k:Means<em>and</em>Hierarchical … - Santini.” Accessed November 8, 2022. http://santini.se/teaching/ml/2016/Lect_10/10c_UnsupervisedMethods.pdf.</li>
<li>“Clustering Analysis - Computer Science | Western Michigan University.” Accessed November 10, 2022. https://cs.wmich.edu/alfuqaha/summer14/cs6530/lectures/ClusteringAnalysis.pdf.</li>
<li>Ajitesh Kumar. “Elbow Method vs Silhouette Score - Which Is Better?” Data Analytics, November 28, 2021. https://vitalflux.com/elbow-method-silhouette-score-which-better/#:~:text=The%20elbow%20method%20is%20used,cluster%20or%20across%20different%20clusters.</li>
<li>Mohantysandip. “A Step by Step approach to Solve DBSCAN Algorithms by tuning its hyper parameters” Medium, March 12, 2020. https://medium.com/<span class="citation" data-cites="mohantysandip/a-step-by-step-approach-to-solve-dbscan-algorithms-by-tuning-its-hyper-parameters-93e693a91289">@mohantysandip/a-step-by-step-approach-to-solve-dbscan-algorithms-by-tuning-its-hyper-parameters-93e693a91289</span></li>
<li>D Andrew. “Text Clustering with TF-IDF in Python” Medium, November 24, 2020. https://medium.com/mlearning-ai/text-clustering-with-tf-idf-in-python-c94cd26a31e7</li>
</ul>
</blockquote>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>